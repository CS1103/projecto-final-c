# Proyecto Final 2025-1: AI Neural Network
## **CS2013 Programaci√≥n III** ¬∑ Informe Final

### **Descripci√≥n**

Implementaci√≥n de una red neuronal multicapa en C++ para el juego Pong, desarrollando desde cero un framework completo de redes neuronales artificiales sin dependencias externas especializadas.

### Contenidos

1. [Datos generales](#datos-generales)
2. [Requisitos e instalaci√≥n](#requisitos-e-instalaci√≥n)
3. [Investigaci√≥n te√≥rica](#1-investigaci√≥n-te√≥rica)
4. [Dise√±o e implementaci√≥n](#2-dise√±o-e-implementaci√≥n)
5. [Ejecuci√≥n](#3-ejecuci√≥n)
6. [An√°lisis del rendimiento](#4-an√°lisis-del-rendimiento)
7. [Trabajo en equipo](#5-trabajo-en-equipo)
8. [Conclusiones](#6-conclusiones)
9. [Bibliograf√≠a](#7-bibliograf√≠a)
10. [Licencia](#licencia)

---

### Datos generales

* **Tema**: Redes Neuronales en AI aplicadas al juego Pong
* **Grupo**: `C--`
* **Integrantes**:

  * **Varela Villarreal, Yeimi Adelmar** ‚Äì 202410586
  * **Guerrero Gutierrez, Nayeli Bel√©n** ‚Äì 202410790 
  * **Medina Patrick** ‚Äì (completar c√≥digo)
  * **Araoz Arana, Fali Ferdinand** ‚Äì 202410721 
  * **Vidal Garcia Ignacio** ‚Äì (completar c√≥digo) 
  * **Bousssus Huerta Guillaume** ‚Äì 202410017

---

### Requisitos e instalaci√≥n

1. **Compilador**: GCC 11 o superior / MSVC 2019+
2. **Dependencias**:

   * CMake 3.18+
   * C++20 est√°ndar
   * Ninguna librer√≠a externa especializada (implementaci√≥n propia)

3. **Instalaci√≥n**:

   ```bash
   git clone git@github.com:CS1103/projecto-final-c.git
   cd projecto-final-c/Proyecto
   mkdir build && cd build
   cmake ..
   make
   ```

> *Comandos para compilaci√≥n en Windows y Linux.*

---

### 1. Investigaci√≥n te√≥rica

* **Objetivo**: Explorar fundamentos y arquitecturas de redes neuronales aplicadas al aprendizaje autom√°tico.
* **Contenido desarrollado**:

  1. Historia y evoluci√≥n de las NNs.
  2. Principales arquitecturas: MLP, CNN, RNN.
  3. Algoritmos de entrenamiento: backpropagation, optimizadores.

#### 1.1 Historia y evoluci√≥n de las NNs

##### Introducci√≥n Te√≥rica
Las redes neuronales artificiales (RNA) constituyen la base del aprendizaje profundo y representan uno de los avances m√°s significativos en redes neuronales. Inspiradas en el funcionamiento del cerebro humano, estas estructuras computacionales permiten resolver problemas complejos que los algoritmos tradicionales no pueden abordar eficientemente. Este informe explora sus fundamentos te√≥ricos, evoluci√≥n hist√≥rica, arquitecturas principales y algoritmos de entrenamiento, proporcionando una base s√≥lida para implementaciones pr√°cticas.

##### Or√≠genes y Desarrollo Hist√≥rico

Dado el nacimiento de la inform√°tica moderna con la invenci√≥n de la m√°quina de Turing en los 40s, la curiosidad por determinar lo que era computable o no eran la base de motivaci√≥n de muchos autores por querer conocer la supremac√≠a de la tecnolog√≠a sobre los humanos. De ah√≠ el test de Turing. Ambivalentemente, dos grandes como el neur√≥logo Warren McCulloch y el matem√°tico Walter Pitts, motivados por la fuente de inteligencia humana, establecieron la primera arquitectura matem√°tica de una neurona artificial. El concepto surgi√≥ dado este modelo.

Donald Hebb (1949) conocido tambi√©n como el padre de la neuropsicolog√≠a, dio a conocer el concepto abstracto de la "mente" con funciones cerebrales fisiol√≥gicas y biol√≥gicas espec√≠ficas. Denomin√≥ el aprendizaje Hebbiano, definiendo que las neuronas forman redes y almacenan informaci√≥n en forma de recuerdos. "Las neuronas que se disparan juntas, se conectan" (Milner, 2003 p.1).

Frank Rosenblatt (1958) desarroll√≥ el perceptr√≥n, la primera red neuronal inspirado en el ojo de una mosca. Su importancia radica en ser un modelo fundamental para la clasificaci√≥n de datos. Fue limitado, porque solo era efectivo para funciones lineales; esto fue demostrado por Marvin Minsky y Seymour Papert (1969) generando en la comunidad de conocedores una desilusi√≥n que termin√≥ frenando la investigaci√≥n sobre redes neuronales. Este tiempo se conoci√≥ como el "Invierno de la IA" que dur√≥ varias d√©cadas entre finales de los 70 y finales de los 80 (Liu, 2024).

En 1986, David Rumelhart, Geoffrey Hinton y Ronald Williams publican un art√≠culo que presenta el algoritmo de back-propagation. Con ello las investigaciones resurgieron. Este procedimiento permite el entrenamiento eficiente de redes neuronales multicapa al ajustar los pesos de las conexiones para minimizar la diferencia entre la salida real y la salida deseada (Rumelhart et al., 1986).

Avances como las redes convolucionales denominadas como CNN (LeCun, 1998) y el Pacto de Toledo (1995) para estabilidad financiera de sistemas, junto con aumentos en capacidad computacional, impulsaron aplicaciones pr√°cticas. Desde 2012, modelos como Transformers han revolucionado √°reas como procesamiento de lenguaje natural (Data Science Academy, 2025).

En 2006, Geoffrey Hinton contribuy√≥ al desarrollo de las Deep Belief Networks (DBN), que utilizan preentrenamiento no supervisado para facilitar el entrenamiento de redes neuronales profundas. La introducci√≥n de las DBN marc√≥ un hito en el avance del aprendizaje profundo, impulsando su aplicaci√≥n en diversas √°reas de la redes neuronales (Hinton y Osindero, 2006).

En 2012, Geoffrey Hinton y su equipo introdujeron AlexNet, un modelo de clasificaci√≥n de im√°genes que transform√≥ el aprendizaje profundo. Este evento clave demostr√≥ las fortalezas de las arquitecturas de redes neuronales convolucionales (CNN) y sus amplias aplicaciones (Kingler, 2024).

Actualmente, las redes neuronales han alcanzado un nivel avanzado de sofisticaci√≥n, impulsadas por modelos de lenguaje grande (LLM) como GPT-4, que mejoran la comprensi√≥n y generaci√≥n de texto. Las redes neuronales convolucionales (CNN) dominan la visi√≥n por computadora, mientras que las redes generativas, como las GAN, producen contenido original de alta calidad. La transferencia de aprendizaje se ha vuelto est√°ndar, facilitando la adaptaci√≥n a nuevas tareas con pocos datos. Adem√°s, se presta atenci√≥n a la √©tica y la mitigaci√≥n de sesgos en la IA, y las redes neuronales est√°n revolucionando el diagn√≥stico m√©dico y la personalizaci√≥n de tratamientos. La integraci√≥n de datos multimodales y el avance del hardware especializado contin√∫an acelerando el desarrollo y la implementaci√≥n de estas tecnolog√≠as en diversas industrias.

##### Timeline de Desarrollo de las Redes Neuronales

| A√±o | Hito |
|-----|------|
| 1943 | **Modelo McCulloch-Pitts**: Warren McCulloch y Walter Pitts proponen un modelo de neuronas artificiales usando circuitos el√©ctricos, sentando las bases para las redes neuronales |
| 1949 | **Aprendizaje Hebbiano**: Donald Hebb introduce el concepto de que las v√≠as neuronales se fortalecen con la activaci√≥n repetida, influyendo en modelos de aprendizaje posteriores |
| 1958 | **Desarrollo del Perceptr√≥n**: Frank Rosenblatt desarrolla el perceptr√≥n, una red neuronal temprana capaz de aprender de datos, limitada a tareas linealmente separables |
| 1969 | **Publicaci√≥n de "Perceptrons"**: Minsky y Papert destacan las limitaciones de los perceptrones, particularmente su incapacidad para resolver problemas no lineales, llevando a una disminuci√≥n del inter√©s en las redes neuronales |
| 1970s-1980s | **Invierno de la IA**: Un per√≠odo de reducci√≥n de financiamiento e investigaci√≥n en IA y redes neuronales debido a las limitaciones destacadas por Minsky y Papert |
| 1986 | **Redescubrimiento de la Retropropagaci√≥n**: Investigadores como Paul Werbos y David Rumelhart reviven el inter√©s en las redes neuronales con la introducci√≥n de la retropropagaci√≥n para entrenar redes multicapa |
| 1989 | **Redes Neuronales Convolucionales (CNNs)**: Yann LeCun introduce las CNNs, mejorando las capacidades de reconocimiento de im√°genes y demostrando aplicaciones pr√°cticas del aprendizaje profundo |
| 2006 | **Resurgimiento del Aprendizaje Profundo**: Geoffrey Hinton y otros introducen las redes de creencia profunda, marcando un resurgimiento en la investigaci√≥n del aprendizaje profundo |
| 2012 | **Avance de AlexNet**: AlexNet de Alex Krizhevsky gana la competencia ImageNet, mostrando el poder del aprendizaje profundo en la clasificaci√≥n de im√°genes |
| 2020s | **Arquitecturas Transformadoras**: La emergencia de arquitecturas transformer revoluciona el procesamiento de lenguaje natural y otros campos, avanzando a√∫n m√°s las capacidades de IA |

*Nota: Referenciado por Codewave (2024)*

#### 1.2 Principales arquitecturas: MLP, CNN, RNN

Despu√©s de revisar la historia de las redes neuronales, es relevante mencionar las 3 arquitecturas de estas:

* MLP (Multilayer Perceptron): Una MLP es una red neuronal compuesta por capas de neuronas completamente conectadas. Rumelhart, Hinton y Williams, (1986) ‚ÄúLas redes multicapa permite representar funciones no lineales mediante la combinaci√≥n de m√∫ltiples capas con funciones de activaci√≥n no lineales‚Äù. Esto quiere decir que una MLP puede aproximar cualquier funci√≥n continua con la cantidad ideal de neuronas y capas.
  Esta estructura cuenta con capas de entrada, capas ocultas y una capa de salida.

* CNN (Convolutional Neural Network): Las CNN est√°n dise√±adas para procesar datos como im√°genes. A diferencia de las MLP, usan capas que comparten pesos y se enfocan en regiones locales del espacio de entrada. LeCun et al., (1998) dicen que ‚ÄúLas convoluciones permiten a la red detectar caracter√≠sticas espaciales locales de manera eficiente y con menos par√°metros‚Äù. Esta estructura cuenta con capas de convoluci√≥n, capas de activaci√≥n, capas de pooling y capas totalmente conectadas.

* RNN (Recurrent Neural Network): Las RNN son redes neuronales utilizadas para modelar datos donde el orden importa, como en texto, audio o series temporales. Incorporan una memoria interna que permite tener en cuenta entradas pasadas. Esta arquitectura cuenta con capas recurrentes, capas GRU (Gated Recurrent Unit), y capas LSTM (Long Short Term Memory) ‚ÄúLas LSTM pueden recordar informaci√≥n durante largos per√≠odos gracias a su estructura de memoria controlada por compuertas‚Äù (Hochreiter & Schmidhuber, 1997).



#### 1.3 Algoritmos de entrenamiento: backpropagation, optimizadores
Por √∫ltimo, es importante revisar los algoritmos de entrenamiento utilizados para alimentar las redes neuronales.

* Backpropagation: El algoritmo de backpropagation, formalizado por Rumelhart, Hinton y Williams en 1986 consiste en utilizar la regla de la cadena para calcular los gradientes de la funci√≥n de p√©rdida con respecto a cada peso en la red, desde la capa de salida hacia la capa de entrada. Esta retropropagaci√≥n permite ajustar los pesos para minimizar el error del modelo. Este es esencial para minimizar el error durante el aprendizaje supervisado.
* Optimizadores: En este caso, hablaremos sobre un optimizador espec√≠fico: Adam. El optimizador Adam (Adaptive Moment Estimation), propuesto por Kingma y Ba en 2014, combina las ventajas de algoritmos anteriores: utiliza la media y varianza de gradientes, ajustando la tasa de aprendizaje para cada par√°metro. Adem√°s, corrige el sesgo inicial en las estimaciones y requiere poco ajuste manual. Esto lo hace particularmente efectivo en redes profundas entrenadas con datos grandes y ruidosos

---

### 2. Dise√±o e implementaci√≥n

#### 2.1 Arquitectura de la soluci√≥n

* **Patrones de dise√±o implementados**: Factory para creaci√≥n de capas, Strategy para optimizadores, Observer para monitoreo de entrenamiento.
* **Estructura de carpetas del proyecto**:

  ```
  Proyecto/
  ‚îú‚îÄ‚îÄ CMakeLists.txt
  ‚îú‚îÄ‚îÄ pong_ascii.cpp/h          # Visualizaci√≥n del juego
  ‚îú‚îÄ‚îÄ train_pong.cpp            # Entrenamiento principal
  ‚îú‚îÄ‚îÄ utils.h                   # Utilidades generales
  ‚îú‚îÄ‚îÄ include/utec/
  ‚îÇ   ‚îú‚îÄ‚îÄ algebra/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tensor.h          # Sistema de tensores
  ‚îÇ   ‚îú‚îÄ‚îÄ nn/
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neural_network.h  # Red neuronal principal
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dense.h           # Capas densas
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activation.h      # Funciones de activaci√≥n
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimizer.h       # Optimizadores
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loss.h            # Funciones de p√©rdida
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ interfaces.h      # Interfaces polim√≥rficas
  ‚îÇ   ‚îî‚îÄ‚îÄ agent/
  ‚îÇ       ‚îú‚îÄ‚îÄ PongAgent.h       # Agente inteligente
  ‚îÇ       ‚îú‚îÄ‚îÄ EnvGym.h          # Entorno de simulaci√≥n
  ‚îÇ       ‚îî‚îÄ‚îÄ state.h           # Estado del juego
  ‚îî‚îÄ‚îÄ tests/                    # Pruebas unitarias
  ```

#### 2.2 Manual de uso y casos de prueba

* **C√≥mo ejecutar el proyecto**:
  ```bash
  # Compilar el proyecto
  cd Proyecto/cmake-build-debug
  
  # Ejecutar entrenamiento
  ./train_pong.exe
  
  # Ejecutar simulaci√≥n visual
  ./Proyecto.exe
  ```

* **Casos de prueba implementados**:
  * Test unitario de tensores multidimensionales
  * Test de capa densa con forward/backward pass
  * Test de funci√≥n de activaci√≥n ReLU
  * Test de convergencia del algoritmo Adam
  * Test de rendimiento del agente en Pong

> *Archivos de prueba ubicados en la carpeta `tests/`*

---

### 3. Ejecuci√≥n



**Pasos para ejecutar:**
1. Correr el archivo train_pong.cpp para iniciar el entrenamiento del agente y guardar el modelo entrenado. Despu√©s de 10,000 √©pocas, el agente deber√≠a aprender a jugar Pong.



### 4. An√°lisis del rendimiento

* **M√©tricas de ejemplo**:

    * Iteraciones: 10 000 √©pocas(50 por lote).
    * Tiempo total de entrenamiento: 1h20m.
    * Precisi√≥n final: 75.8%.

* **Configuraci√≥n de exploraci√≥n:**:
    * Epsilon inicial: 1
    * Decay de Epsilon: 0.9995
    * Epsilon m√≠nimo: 0.1

* **Ventajas/Desventajas**:


  üü¢ VENTAJAS
1. **Arquitectura Modular y Bien Estructurada**

   Separaci√≥n clara de responsabilidades: Tensor, Neural Network, Agent, Environment
   Uso de templates: Permite flexibilidad de tipos de datos (float, double)
   Namespaces organizados: utec::algebra, utec::nn, utec::pong
2. **Implementaci√≥n Completa de Tensor**

   Soporte multidimensional: Tensores N-dimensionales con strides
   Broadcasting: Operaciones entre tensores de diferentes formas
   Operadores sobrecargados: +, -, *, / para operaciones matem√°ticas
   Matrix multiplication: Soporte para productos matriciales 2D y 3D
3. **Red Neuronal Funcional**

   Arquitectura flexible: Capas densas, activaciones (ReLU, Sigmoid)
   Sistema de capas: Interfaz ILayer<T> para extensibilidad
   Optimizadores: Implementaci√≥n de optimizadores de gradiente
4. **Agente de IA Robusto**

   Epsilon-greedy: Balance entre exploraci√≥n y explotaci√≥n
   Entrenamiento por lotes: Eficiencia en el aprendizaje
   Estrategia h√≠brida: Combina reglas heur√≠sticas con aprendizaje
5. **Visualizaci√≥n y Debugging**

   Simulaci√≥n ASCII: Visualizaci√≥n en consola del juego
   M√©tricas de progreso: Seguimiento del entrenamiento
   Configuraci√≥n UTF-8: Soporte para caracteres especiales
   
üî¥ DESVENTAJAS

1. **Limitaciones del Algoritmo**

   Sin backpropagation real: El entrenamiento no actualiza pesos
   Aprendizaje supervisado b√°sico. No implementa Q-learning o Policy Gradient
   Estrategia heur√≠stica dominante. El modelo neuronal tiene poco impacto
2. **Problemas de Rendimiento**

   C√°lculos secuenciales: No aprovecha paralelizaci√≥n
   
    Memoria ineficiente: Copias innecesarias de tensores
   
    Sin optimizaciones: No usa BLAS o SIMD
3. **Falta de Robustez**

   Manejo de errores b√°sico: Excepciones simples

   Sin validaci√≥n de entrada: No verifica par√°metros

   Configuraci√≥n hardcodeada: Par√°metros fijos en el c√≥digo

* **Mejoras futuras**:

    * Uso de BLAS para multiplicaciones.




### 5. Trabajo en equipo

| Tarea | Miembro            | Rol |
|-------|--------------------|-----|
| Investigaci√≥n te√≥rica | Patrick Medina     | Documentar bases te√≥ricas e historia de NNs |
| Desarrollo de arquitectura | Ignacio Vidal      | Dise√±o UML y esquemas de clases |
| Implementaci√≥n del modelo | Yeimi Varela       | C√≥digo C++ del framework neuronal |
| Pruebas y benchmarking | Nayeli Guerrero    | Generaci√≥n de m√©tricas y testing |
| Documentaci√≥n y demo | Fali Araoz         | Tutorial y demostraci√≥n del sistema |
| An√°lisis de rendimiento | Guillaume Bousssus | Evaluaci√≥n y optimizaci√≥n de performance |

> *Distribuci√≥n de responsabilidades del equipo de desarrollo.*

---

### 6. Conclusiones

El proyecto Pong con redes neuronales representa una implementaci√≥n completa y ambiciosa de un sistema de aprendizaje autom√°tico desarrollado √≠ntegramente en C++ moderno, sin depender de bibliotecas externas. A trav√©s de este trabajo se demuestra la aplicaci√≥n pr√°ctica de conceptos fundamentales de machine learning, √°lgebra lineal computacional y programaci√≥n orientada a objetos en el contexto de un juego cl√°sico, integrando m√∫ltiples disciplinas de forma rigurosa y estructurada.

La arquitectura del sistema ha sido dise√±ada con un enfoque modular, separando claramente las responsabilidades entre los distintos componentes: el n√∫cleo matem√°tico de tensores, la implementaci√≥n de redes neuronales, el agente de IA y el entorno de simulaci√≥n. El sistema de tensores N-dimensionales constituye la base computacional del proyecto, proporcionando operaciones como broadcasting autom√°tico, multiplicaci√≥n matricial optimizada y manipulaci√≥n eficiente de estructuras de datos multidimensionales. Esta infraestructura matem√°tica permite implementar algoritmos de aprendizaje sin depender de herramientas externas, lo cual refuerza el entendimiento profundo de los fundamentos del machine learning.

Sobre esta base se construye una red neuronal flexible y extensible mediante un sistema de capas dise√±adas con el patr√≥n de dise√±o Strategy, lo que facilita su modificaci√≥n y evoluci√≥n. Se incluyen capas densas completamente conectadas, funciones de activaci√≥n como ReLU y Sigmoid, y una estructura preparada para incorporar optimizadores de gradiente en el futuro. El agente de redes neuronales utiliza una estrategia h√≠brida que combina reglas heur√≠sticas iniciales con aprendizaje basado en experiencia, empleando una pol√≠tica de exploraci√≥n epsilon-greedy para mejorar progresivamente su rendimiento a trav√©s del juego.

El entorno de simulaci√≥n, inspirado en la filosof√≠a de interfaces como OpenAI Gym, permite una interacci√≥n limpia y coherente entre el agente y el juego. Esto facilita tanto el proceso de entrenamiento como la evaluaci√≥n del modelo. Para la visualizaci√≥n, se opt√≥ por una interfaz en consola basada en caracteres ASCII, lo que ofrece una manera sencilla pero efectiva de observar en tiempo real el comportamiento del agente sin necesidad de librer√≠as gr√°ficas.

A nivel t√©cnico, el proyecto destaca por su uso avanzado de caracter√≠sticas modernas de C++, incluyendo templates gen√©ricos, gesti√≥n autom√°tica de memoria mediante el principio RAII, y sobrecarga de operadores para operaciones matem√°ticas intuitivas. Esta aproximaci√≥n demuestra no solo habilidades avanzadas en programaci√≥n, sino tambi√©n un conocimiento profundo del lenguaje y su aplicabilidad a sistemas de alto rendimiento.

No obstante, el sistema a√∫n presenta ciertas limitaciones que abren oportunidades claras para desarrollos futuros. La implementaci√≥n actual del algoritmo de backpropagation no actualiza correctamente los pesos de la red neuronal, lo que restringe la capacidad de aprendizaje del modelo. Asimismo, la configuraci√≥n del entrenamiento est√° codificada de forma est√°tica, lo que dificulta la experimentaci√≥n con diferentes hiperpar√°metros. La interfaz de usuario limitada a consola podr√≠a ampliarse con herramientas gr√°ficas para facilitar la visualizaci√≥n de m√©tricas y la manipulaci√≥n del entrenamiento. Por otro lado, la cobertura de pruebas automatizadas es parcial y podr√≠a ampliarse para abarcar casos l√≠mite y validar algoritmos cr√≠ticos con mayor rigor.

En conclusi√≥n, el proyecto de Pong con redes neuronales constituye un logro t√©cnico significativo que combina teor√≠a y pr√°ctica de manera ejemplar. No solo cumple con su objetivo educativo de demostrar c√≥mo se construye un sistema de machine learning desde cero, sino que tambi√©n establece una base t√©cnica s√≥lida para futuras investigaciones o desarrollos profesionales en redes neuronales y programaci√≥n en C++. Su enfoque riguroso, su arquitectura bien definida y su ejecuci√≥n t√©cnica detallada convierten a este proyecto en un excelente ejemplo de integraci√≥n disciplinaria y una valiosa adici√≥n a cualquier portafolio profesional enfocado en redes neuronales y desarrollo de software de alto rendimiento.

---

### 7. Bibliograf√≠a

[1] Data Science Academy. (2025). "Cap√≠tulo 10 ‚Äì As Principais Arquiteturas de Redes Neurais," *Deep Learning Book*. [Online]. Available: https://www.deeplearningbook.com.br/as-principais-arquiteturas-de-redes-neurais/

[2] CodeWave. (2024). "History and Development of Neural Networks in AI." [Online]. Available: https://codewave.com/insights/development-of-neural-networks-history/

[3] P. Milner, "A Brief History of the Hebbian Learning Rule," *Canadian Psychology/Psychologie canadienne*, vol. 44, pp. 5-9, 2003. DOI: 10.1037/h0085817

[4] D. Rumelhart, G. Hinton, and R. Williams, "Learning representations by back-propagating errors," *Nature*, vol. 323, pp. 533-536, 1986. DOI: 10.1038/323533a0

[5] Y. Liu, "The Perceptron Controversy," *Yuxi on the Wired*, 2024. [Online]. Available: https://yuxi-liu-wired.github.io/essays/posts/perceptron-controversy/

[6] N. Schaetti, "A Short history of Artificial Intelligence and Neural Network," *LinkedIn*, 2018. [Online]. Available: https://www.linkedin.com/pulse/short-history-artificial-intelligence-neural-network-nils

[7] G. E. Hinton and S. Osindero, "A fast learning algorithm for deep belief nets." [Online]. Available: https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf

[8] N. Kingler, "AlexNet: A Revolutionary Deep Learning Architecture," *Viso.ai*, 2024. [Online]. Available: https://viso.ai/deep-learning/alexnet/

[9] S. Haykin, *Neural Networks and Learning Machines*, Prentice Hall, 2009. [Online]. Available: https://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf

---

### Licencia

Este proyecto usa la licencia **MIT**. Ver [LICENSE](LICENSE) para m√°s detalles.

---
